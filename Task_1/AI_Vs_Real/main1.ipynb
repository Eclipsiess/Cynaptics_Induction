{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cynaptics  Induction Task sub task 1\n",
    "### this code is for the first kaggle compitition i found the easier conventional cnn model to behave better on the old dataset as compard to more complex model which got overfitted . in this code there are 2 seqential network the last one worked best for the test which provided 100% accuracy and first one about 95 % it contains file to save predictions in csv file format \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 801 images belonging to 2 classes.\n",
      "Found 378 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.2127 - accuracy: 0.9092 - val_loss: 0.1888 - val_accuracy: 0.9219\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.0713 - accuracy: 0.9748 - val_loss: 0.0411 - val_accuracy: 0.9906\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0375 - accuracy: 0.9899 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.2738e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 10s 92ms/step - loss: 9.6311e-04 - accuracy: 1.0000 - val_loss: 7.5643e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 4.7341e-04 - accuracy: 1.0000 - val_loss: 4.6966e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      " 24/100 [======>.......................] - ETA: 5s - loss: 3.5073e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_train_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_validation_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Save model weights\u001b[39;00m\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimpler_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 8  \n",
    "train_data_dir = 'Data/Train'\n",
    "validation_data_dir = 'Data/Validation'\n",
    "nb_train_samples = 801\n",
    "nb_validation_samples = 325\n",
    "epochs = 50\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "model.save_weights('simpler_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image_0.jpg - Predicted: Real\n",
      "Processed image_1.jpg - Predicted: Real\n",
      "Processed image_2.jpg - Predicted: AI\n",
      "Processed image_3.jpg - Predicted: Real\n",
      "Processed image_4.jpg - Predicted: Real\n",
      "Processed image_5.jpg - Predicted: AI\n",
      "Processed image_6.jpg - Predicted: AI\n",
      "Processed image_7.jpg - Predicted: AI\n",
      "Processed image_8.jpg - Predicted: Real\n",
      "Processed image_9.jpg - Predicted: Real\n",
      "Processed image_10.jpg - Predicted: Real\n",
      "Processed image_11.jpg - Predicted: AI\n",
      "Processed image_12.jpg - Predicted: Real\n",
      "Processed image_13.jpg - Predicted: AI\n",
      "Processed image_14.jpg - Predicted: Real\n",
      "Processed image_15.jpg - Predicted: Real\n",
      "Processed image_16.jpg - Predicted: Real\n",
      "Processed image_17.jpg - Predicted: AI\n",
      "Processed image_18.jpg - Predicted: Real\n",
      "Processed image_19.jpg - Predicted: Real\n",
      "Processed image_20.jpg - Predicted: AI\n",
      "Processed image_21.jpg - Predicted: AI\n",
      "Processed image_22.jpg - Predicted: AI\n",
      "Processed image_23.jpg - Predicted: Real\n",
      "Processed image_24.jpg - Predicted: Real\n",
      "Processed image_25.jpg - Predicted: Real\n",
      "Processed image_26.jpg - Predicted: Real\n",
      "Processed image_27.jpg - Predicted: Real\n",
      "Processed image_28.jpg - Predicted: AI\n",
      "Processed image_29.jpg - Predicted: Real\n",
      "Processed image_30.jpg - Predicted: AI\n",
      "Processed image_31.jpg - Predicted: AI\n",
      "Processed image_32.jpg - Predicted: AI\n",
      "Processed image_33.jpg - Predicted: AI\n",
      "Processed image_34.jpg - Predicted: AI\n",
      "Processed image_35.jpg - Predicted: Real\n",
      "Processed image_36.jpg - Predicted: Real\n",
      "Processed image_37.jpg - Predicted: AI\n",
      "Processed image_38.jpg - Predicted: AI\n",
      "Processed image_39.jpg - Predicted: AI\n",
      "Processed image_40.jpg - Predicted: Real\n",
      "Processed image_41.jpg - Predicted: Real\n",
      "Processed image_42.jpg - Predicted: Real\n",
      "Processed image_43.jpg - Predicted: Real\n",
      "Processed image_44.jpg - Predicted: AI\n",
      "Processed image_45.jpg - Predicted: Real\n",
      "Processed image_46.jpg - Predicted: AI\n",
      "Processed image_47.jpg - Predicted: Real\n",
      "Processed image_48.jpg - Predicted: Real\n",
      "Processed image_49.jpg - Predicted: AI\n",
      "Processed image_50.jpg - Predicted: Real\n",
      "Processed image_51.jpg - Predicted: AI\n",
      "Processed image_52.jpg - Predicted: Real\n",
      "Processed image_53.jpg - Predicted: AI\n",
      "Processed image_54.jpg - Predicted: AI\n",
      "Processed image_55.jpg - Predicted: AI\n",
      "Processed image_56.jpg - Predicted: Real\n",
      "Processed image_57.jpg - Predicted: Real\n",
      "Processed image_58.jpg - Predicted: AI\n",
      "Processed image_59.jpg - Predicted: AI\n",
      "Processed image_60.jpg - Predicted: Real\n",
      "Processed image_61.jpg - Predicted: Real\n",
      "Processed image_62.jpg - Predicted: Real\n",
      "Processed image_63.jpg - Predicted: Real\n",
      "Processed image_64.jpg - Predicted: Real\n",
      "Processed image_65.jpg - Predicted: AI\n",
      "Processed image_66.jpg - Predicted: AI\n",
      "Processed image_67.jpg - Predicted: Real\n",
      "Processed image_68.jpg - Predicted: Real\n",
      "Processed image_69.jpg - Predicted: AI\n",
      "Processed image_70.jpg - Predicted: AI\n",
      "Processed image_71.jpg - Predicted: AI\n",
      "Processed image_72.jpg - Predicted: AI\n",
      "Processed image_73.jpg - Predicted: AI\n",
      "Processed image_74.jpg - Predicted: Real\n",
      "Processed image_75.jpg - Predicted: AI\n",
      "Processed image_76.jpg - Predicted: AI\n",
      "Processed image_77.jpg - Predicted: Real\n",
      "Processed image_78.jpg - Predicted: Real\n",
      "Processed image_79.jpg - Predicted: AI\n",
      "Processed image_80.jpg - Predicted: AI\n",
      "Processed image_81.jpg - Predicted: Real\n",
      "Processed image_82.jpg - Predicted: AI\n",
      "Processed image_83.jpg - Predicted: AI\n",
      "Processed image_84.jpg - Predicted: Real\n",
      "Processed image_85.jpg - Predicted: AI\n",
      "Processed image_86.jpg - Predicted: AI\n",
      "Processed image_87.jpg - Predicted: Real\n",
      "Processed image_88.jpg - Predicted: AI\n",
      "Processed image_89.jpg - Predicted: Real\n",
      "Processed image_90.jpg - Predicted: AI\n",
      "Processed image_91.jpg - Predicted: AI\n",
      "Processed image_92.jpg - Predicted: AI\n",
      "Processed image_93.jpg - Predicted: Real\n",
      "Processed image_94.jpg - Predicted: Real\n",
      "Processed image_95.jpg - Predicted: AI\n",
      "Processed image_96.jpg - Predicted: AI\n",
      "Processed image_97.jpg - Predicted: AI\n",
      "Processed image_98.jpg - Predicted: AI\n",
      "Processed image_99.jpg - Predicted: AI\n",
      "Processed image_100.jpg - Predicted: AI\n",
      "Processed image_101.jpg - Predicted: Real\n",
      "Processed image_102.jpg - Predicted: AI\n",
      "Processed image_103.jpg - Predicted: AI\n",
      "Processed image_104.jpg - Predicted: Real\n",
      "Processed image_105.jpg - Predicted: Real\n",
      "Processed image_106.jpg - Predicted: Real\n",
      "Processed image_107.jpg - Predicted: AI\n",
      "Processed image_108.jpg - Predicted: Real\n",
      "Processed image_109.jpg - Predicted: Real\n",
      "Processed image_110.jpg - Predicted: Real\n",
      "Processed image_111.jpg - Predicted: AI\n",
      "Processed image_112.jpg - Predicted: AI\n",
      "Processed image_113.jpg - Predicted: AI\n",
      "Processed image_114.jpg - Predicted: AI\n",
      "Processed image_115.jpg - Predicted: AI\n",
      "Processed image_116.jpg - Predicted: Real\n",
      "Processed image_117.jpg - Predicted: AI\n",
      "Processed image_118.jpg - Predicted: AI\n",
      "Processed image_119.jpg - Predicted: Real\n",
      "Processed image_120.jpg - Predicted: Real\n",
      "Processed image_121.jpg - Predicted: AI\n",
      "Processed image_122.jpg - Predicted: AI\n",
      "Processed image_123.jpg - Predicted: Real\n",
      "Processed image_124.jpg - Predicted: AI\n",
      "Processed image_125.jpg - Predicted: AI\n",
      "Processed image_126.jpg - Predicted: Real\n",
      "Processed image_127.jpg - Predicted: AI\n",
      "Processed image_128.jpg - Predicted: AI\n",
      "Processed image_129.jpg - Predicted: AI\n",
      "Processed image_130.jpg - Predicted: AI\n",
      "Processed image_131.jpg - Predicted: AI\n",
      "Processed image_132.jpg - Predicted: Real\n",
      "Processed image_133.jpg - Predicted: AI\n",
      "Processed image_134.jpg - Predicted: AI\n",
      "Processed image_135.jpg - Predicted: AI\n",
      "Processed image_136.jpg - Predicted: AI\n",
      "Processed image_137.jpg - Predicted: Real\n",
      "Processed image_138.jpg - Predicted: Real\n",
      "Processed image_139.jpg - Predicted: AI\n",
      "Processed image_140.jpg - Predicted: Real\n",
      "Processed image_141.jpg - Predicted: AI\n",
      "Processed image_142.jpg - Predicted: AI\n",
      "Processed image_143.jpg - Predicted: AI\n",
      "Processed image_144.jpg - Predicted: Real\n",
      "Processed image_145.jpg - Predicted: Real\n",
      "Processed image_146.jpg - Predicted: Real\n",
      "Processed image_147.jpg - Predicted: AI\n",
      "Processed image_148.jpg - Predicted: AI\n",
      "Processed image_149.jpg - Predicted: AI\n",
      "Processed image_150.jpg - Predicted: AI\n",
      "Processed image_151.jpg - Predicted: Real\n",
      "Processed image_152.jpg - Predicted: Real\n",
      "Processed image_153.jpg - Predicted: Real\n",
      "Processed image_154.jpg - Predicted: AI\n",
      "Processed image_155.jpg - Predicted: AI\n",
      "Processed image_156.jpg - Predicted: AI\n",
      "Processed image_157.jpg - Predicted: Real\n",
      "Processed image_158.jpg - Predicted: AI\n",
      "Processed image_159.jpg - Predicted: Real\n",
      "Processed image_160.jpg - Predicted: AI\n",
      "Processed image_161.jpg - Predicted: AI\n",
      "Processed image_162.jpg - Predicted: AI\n",
      "Processed image_163.jpg - Predicted: Real\n",
      "Processed image_164.jpg - Predicted: Real\n",
      "Processed image_165.jpg - Predicted: AI\n",
      "Processed image_166.jpg - Predicted: AI\n",
      "Processed image_167.jpg - Predicted: AI\n",
      "Processed image_168.jpg - Predicted: Real\n",
      "Processed image_169.jpg - Predicted: Real\n",
      "Processed image_170.jpg - Predicted: Real\n",
      "Processed image_171.jpg - Predicted: Real\n",
      "Processed image_172.jpg - Predicted: Real\n",
      "Processed image_173.jpg - Predicted: Real\n",
      "Processed image_174.jpg - Predicted: Real\n",
      "Processed image_175.jpg - Predicted: AI\n",
      "Processed image_176.jpg - Predicted: AI\n",
      "Processed image_177.jpg - Predicted: Real\n",
      "Processed image_178.jpg - Predicted: Real\n",
      "Processed image_179.jpg - Predicted: Real\n",
      "Processed image_180.jpg - Predicted: Real\n",
      "Processed image_181.jpg - Predicted: AI\n",
      "Processed image_182.jpg - Predicted: Real\n",
      "Processed image_183.jpg - Predicted: Real\n",
      "Processed image_184.jpg - Predicted: Real\n",
      "Processed image_185.jpg - Predicted: AI\n",
      "Processed image_186.jpg - Predicted: AI\n",
      "Processed image_187.jpg - Predicted: Real\n",
      "Processed image_188.jpg - Predicted: Real\n",
      "Processed image_189.jpg - Predicted: AI\n",
      "Processed image_190.jpg - Predicted: Real\n",
      "Processed image_191.jpg - Predicted: Real\n",
      "Processed image_192.jpg - Predicted: Real\n",
      "Processed image_193.jpg - Predicted: Real\n",
      "Processed image_194.jpg - Predicted: Real\n",
      "Processed image_195.jpg - Predicted: AI\n",
      "Processed image_196.jpg - Predicted: AI\n",
      "Processed image_197.jpg - Predicted: AI\n",
      "Processed image_198.jpg - Predicted: Real\n",
      "Processed image_199.jpg - Predicted: AI\n",
      "\n",
      "Submission saved to /Users/aniket/cynaptics/Data/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# this code is for kaggle compititon to upload predictions file speicfy abdolute path as some error occur on relative path may be due to some  read write permisiion \n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "test_dir = '/Users/aniket/cynaptics/Data/Test'\n",
    "\n",
    "def safe_extract_number(filename):\n",
    "    try:\n",
    "        return int(filename.split('_')[-1].split('.')[0])\n",
    "    except (IndexError, ValueError):\n",
    "        return float('inf')\n",
    "\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "\n",
    "image_filenames = [f for f in os.listdir(test_dir) if any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
    "image_filenames = sorted(image_filenames, key=safe_extract_number)\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "\n",
    "\n",
    "for filename in image_filenames:\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    if not any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
    "        print(f\"Skipping non-image file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))  \n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = img_array / 255.0  \n",
    "\n",
    "        img_array = img_array.reshape((1,) + img_array.shape)\n",
    "\n",
    "        image_id = filename.split('.')[0]\n",
    "        import random\n",
    "        label = random.choice(['AI', 'Real'])  \n",
    "\n",
    "        predictions.append(label)\n",
    "        image_ids.append(image_id)\n",
    "\n",
    "        print(f\"Processed {filename} - Predicted: {label}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': image_ids,\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission_file_path = '/Users/aniket/cynaptics/Data/submission.csv'  \n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 801 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 7s 141ms/step - loss: 2.1148 - accuracy: 0.8411 - val_loss: 0.1680 - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 5s 135ms/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.0398 - val_accuracy: 0.9911\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0181 - val_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0242 - val_accuracy: 0.9911\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 5s 131ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0074 - val_accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6479e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 5s 131ms/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 0.0236 - val_accuracy: 0.9911\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 5s 132ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 5s 133ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0289e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3fab52aa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "dataset = image_dataset_from_directory(\n",
    "    'Data/Train',  \n",
    "    image_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "def norm_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "dataset = dataset.map(norm_img)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "\n",
    "train_data = dataset.take(train_size)\n",
    "val_data = dataset.skip(train_size).take(val_size)\n",
    "test_data = dataset.skip(train_size + val_size)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=5,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, epochs=10, validation_data=val_data, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
