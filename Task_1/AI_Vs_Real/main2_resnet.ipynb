{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cynaptics  Induction Task sub task 1\n",
    "### This code is for the second kaggle compitition i found this model to do better in new datset than prev model in this i used  Resnet and added some layers on top of it .i also unfrezzed some layers of the resnet model  accuracy on kaggle test is around 0.63 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150, 150, 3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "len(model.trainable_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir = 'Data/Validation'\n",
    "train_dir = 'Data/Train'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  \n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,  \n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=2e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  \n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze = False  \n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block3_conv1':\n",
    "        unfreeze = True  \n",
    "    if unfreeze:\n",
    "        layer.trainable = True  \n",
    "    else:\n",
    "        layer.trainable = False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model  \n",
    "\n",
    "test_dir = '/Users/aniket/cynaptics/Data/Test'\n",
    "\n",
    "\n",
    "def safe_extract_number(filename):\n",
    "    try:\n",
    "        return int(filename.split('_')[-1].split('.')[0])\n",
    "    except (IndexError, ValueError):\n",
    "        return float('inf')\n",
    "\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "\n",
    "image_filenames = [f for f in os.listdir(test_dir) if any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
    "image_filenames = sorted(image_filenames, key=safe_extract_number)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for filename in image_filenames:\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    if not any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
    "        print(f\"Skipping non-image file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(150, 150))  \n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0 \n",
    "        pred = model.predict(img_array)  \n",
    "\n",
    "        \n",
    "        predicted_class = 'Real' if pred[0] >= 0.5 else 'AI'\n",
    "\n",
    "        \n",
    "        filename_without_extension = os.path.splitext(filename)[0]\n",
    "\n",
    "       \n",
    "        predictions.append((filename_without_extension, predicted_class))\n",
    "\n",
    "        print(f\"Processed {filename} - Predicted: {predicted_class}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(predictions, columns=['Id', 'Label'])\n",
    "\n",
    "submission_file_path = '/Users/aniket/cynaptics/Data/submission.csv' \n",
    "results_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
