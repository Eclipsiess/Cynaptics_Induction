{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This contains many other modle i trained i inlcuded their test result as given by kaggle \n",
    "### many of them may look out of place and there is repitetion of code as they belong to different files which i combined together \n",
    "### i also tried xception model but my it was taking too much time so i decided to drop it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model accuracy - 87 \n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import applications\n",
    "import pandas as pd\n",
    "img_width, img_height = 224, 224  \n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'Data/Train'\n",
    "validation_data_dir = 'Data/Validation'\n",
    "nb_train_samples = 801\n",
    "nb_validation_samples = 325\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict(generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train.npy', bottleneck_features_train) \n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict(generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation.npy', bottleneck_features_validation)  \n",
    "def train_top_model():\n",
    "    train_data = np.load('bottleneck_features_train.npy')  \n",
    "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "    if len(train_labels) < nb_train_samples:\n",
    "        train_labels = np.append(train_labels, 0)  \n",
    "    validation_data = np.load('bottleneck_features_validation.npy')  \n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "    if len(validation_labels) < nb_validation_samples:\n",
    "        validation_labels = np.append(validation_labels, 0) \n",
    "    print(\"Train data shape:\", train_data.shape)\n",
    "    print(\"Train labels shape:\", train_labels.shape)\n",
    "    print(\"Validation data shape:\", validation_data.shape)\n",
    "    print(\"Validation labels shape:\", validation_labels.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    test_dir = '/Users/aniket/cynaptics/Data/Test'\n",
    "    image_filenames = sorted(os.listdir(test_dir), key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    predictions = []\n",
    "    for filename in image_filenames:\n",
    "        img_path = os.path.join(test_dir, filename)\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))  \n",
    "            img_array = img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "            pred = model.predict(img_array)\n",
    "            predicted_class = 'Real' if pred[0] >= 0.5 else 'AI'\n",
    "            filename_without_extension = os.path.splitext(filename)[0]\n",
    "            predictions.append((filename_without_extension, predicted_class))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {filename}: {e}\")\n",
    "    results_df = pd.DataFrame(predictions, columns=['Id', 'Label'])\n",
    "    results_df.to_csv('predictions.csv', index=False)\n",
    "save_bottleneck_features()\n",
    "train_top_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note define val  and train dir for val i randomly selected 50 images from each class \n",
    "\n",
    "import efficientnet.keras as efn\n",
    "train_datagen4 = ImageDataGenerator(\n",
    "    rescale=1. / 255.,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen4 = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.\n",
    ")\n",
    "\n",
    "train_generator4 = train_datagen4.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "validation_generator4 = test_datagen4.flow_from_directory(\n",
    "    val_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "base_model = efn.EfficientNetB0(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense \n",
    "from tensorflow.keras.models import Model  \n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)  \n",
    "predictions = Dense(1, activation=tf.nn.sigmoid)(x)  \n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_final.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "eff_history = model_final.fit(\n",
    "    train_generator4,\n",
    "    validation_data=validation_generator4,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code inception model rest code was same  add test and val  directory \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "train_datagen3 = ImageDataGenerator(\n",
    "    rescale=1. / 255.,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.\n",
    ")\n",
    "train_generator3 = train_datagen3.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150)\n",
    ")\n",
    "\n",
    "validation_generator3 = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150)\n",
    ")\n",
    "\n",
    "\n",
    "base_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model2 = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model2.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "inc_history = model2.fit(\n",
    "    train_generator3,\n",
    "    validation_data=validation_generator3,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thsi code help to create val data and check if it already exist \n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "train_dir = 'your path '  \n",
    "val_dir = 'your path '  \n",
    "\n",
    "# Create validation directory structure\n",
    "os.makedirs(os.path.join(val_dir, 'AI'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'Real'), exist_ok=True)\n",
    "\n",
    "# Function to copy random images\n",
    "def copy_random_images(src_class_dir, dst_class_dir, num_images):\n",
    "    images = os.listdir(src_class_dir)\n",
    "    selected_images = random.sample(images, min(num_images, len(images)))\n",
    "    \n",
    "    for image in selected_images:\n",
    "        shutil.copy(os.path.join(src_class_dir, image), os.path.join(dst_class_dir, image))\n",
    "\n",
    "# Copy images from AI class\n",
    "copy_random_images(os.path.join(train_dir, 'AI'), os.path.join(val_dir, 'AI'), 50)\n",
    "\n",
    "# Copy images from Real class\n",
    "copy_random_images(os.path.join(train_dir, 'Real'), os.path.join(val_dir, 'Real'), 50)\n",
    "\n",
    "print(\"Validation images copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a differet train data generator thatr i applied earlier  but it turned out they decreasce the test performance on kaggle \n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
